---
title: "Big Mart Sales Prediction"
output: 
  html_notebook: 
    fig_height: 8.5
    fig_width: 10
---

The data scientists at BigMart have collected sales data for 1559 products across 10 stores in different cities for the year 2013. Now each product has certain attributes that sets it apart from other products. Same is the case with each store.

The aim is to build a predictive model to find out the sales of each product at a particular store so that it would help the decision makers at BigMart to find out the properties of any product or store, which play a key role in increasing the overall sales.

## Loading Packages
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(readr)
library(gridExtra)
library(randomForest)
library(caret)
library(mlr)
library(knitr)
```

## Importing Data
```{r}
Train <- read_csv("Train.csv")
Test <- read_csv("Test.csv")
```

### Understanding Dataset
```{r}
# Dimension of Data
dim(Train)
dim(Test)

# Structure of Data
str(Train)
str(Test)
```

### Combining Test and Train Dataset
```{r}
Test$Item_Outlet_Sales = NA
All <- rbind(Train,Test)
str(All)
```
## **Data Visualization**

### **Univariate Analysis**
### Target Variable
Since our target variable is continuous, we can visualise it by plotting its histogram.
```{r}
ggplot(Train, aes(Item_Outlet_Sales)) +
  geom_histogram(binwidth = 100, fill = "cadetblue4") + 
    scale_x_continuous(breaks = seq(0,14000, by =1000))
```
As you can see, it is a right skewd variable and would need some data transformation to treat its skewness.

## Independent Variables (Continuous)
```{r warning=FALSE}
p11 <-ggplot(All, aes(Item_Weight)) +
      geom_histogram( fill = "springgreen4", na.rm = TRUE,binwidth = 0.5)+ 
      scale_x_continuous(breaks = seq(0,25, by =2.5))

p12 <-ggplot(All, aes(Item_Visibility)) +
      geom_histogram( fill = "darkorange4", na.rm = TRUE)+ 
      scale_x_continuous(breaks = seq(0,0.5, by =0.05))

p13 <-ggplot(All, aes(Item_MRP)) +
      geom_histogram( fill = "purple4", na.rm = TRUE,binwidth = 5)+ 
      scale_x_continuous(breaks = seq(0,300, by =25))



p31 <- ggplot(All, aes(x= 'Item Weight',y=Item_Weight)) +
          geom_boxplot(outlier.colour = "red4")

p32 <- ggplot(All, aes(x= 'Item_Visibility',y=Item_Visibility)) +
          geom_boxplot(outlier.colour = "red4")

p33 <- ggplot(All, aes(x= 'Item_MRP',y=Item_MRP)) +
          geom_boxplot(outlier.colour = "red4")

grid.arrange(
          p11,p12,p13,p31,p32,p33,nrow = 2,
          top = "Continuous Variable")
```
 * Observations
 * Item_MRP has clear cuts, i.e we can see 4 different distributions
 * Item_Visibility is right-skewed and should be transformed
 * No pattern in Item_Weight
 
### Independent Variables (Categorical)
```{r}
ggplot(All, aes(Item_Fat_Content,fill = Item_Fat_Content)) +
  geom_bar(na.rm = TRUE) + ggtitle("Original Item Fat Content")

# Convert factor in character [Item_Fat_Content]
All$Item_Fat_Content <- as_factor(All$Item_Fat_Content)
# check levels
levels(All$Item_Fat_Content) 

# replace LF,low fat with Low Fat
levels( All$Item_Fat_Content)[3:4] <- "Low Fat"
# replace ref with Regular
levels( All$Item_Fat_Content )[3] <- "Regular"

ggplot(All, aes(Item_Fat_Content,fill = Item_Fat_Content)) +
  geom_bar(na.rm = TRUE) + ggtitle("Modified Item Fat Content")
```
As here we can see Low Fat content item is sold more than the regular item
```{r}
ggplot(All, aes(fct_infreq(Item_Type),fill = Item_Type)) +
  geom_bar( na.rm = TRUE)+ xlab("Item Type") + 
    coord_flip()
```

```{r}
p21 <- ggplot(All, aes(Outlet_Type)) +
        geom_bar(fill = "springgreen4", na.rm = TRUE) + 
          theme(axis.text.x = element_text(angle = 20, hjust = 1))
p22 <- ggplot(All, aes(Outlet_Location_Type )) +
        geom_bar(fill = "purple4", na.rm = TRUE)
p23 <- ggplot(All, aes(Outlet_Size)) +
        geom_bar(fill = "darkorange4", na.rm = TRUE)
p24 <- ggplot(All, aes(factor(Outlet_Establishment_Year))) +
        geom_bar(fill = "darkorange4", na.rm = TRUE) + 
          theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
            xlab("Outlet Establishment Year")
grid.arrange(p21,p22,p23,p24, nrow = 2,
        top = "Categorical variable")
```
* Obsevations
* People likes to go Supermarket Type I the most
* Large no. of missing values in Outlet Size

### **Bivariate Analysis**

Extracting train data from the All Data
```{r}
Train = All[1:nrow(Train),]
```

### Target Variable vs Independent Continuous Variables
```{r warning= FALSE}
# Continuous Vs Target Variable
p61 <- ggplot(Train, aes(Item_Weight,Item_Outlet_Sales))+
        geom_point(colour = 'cadetblue4',alpha=0.3) 
  
p62 <- ggplot(Train, aes(Item_Visibility,Item_Outlet_Sales))+
        geom_point(colour = 'darkseagreen4',alpha=0.3) 

p63 <- ggplot(Train, aes(Item_MRP,Item_Outlet_Sales))+
        geom_point(colour = 'deepskyblue3',alpha=0.3)

grid.arrange(
          p61,
          arrangeGrob(p62,p63,ncol = 2),
          nrow = 2,
          top = "Continuous Vs Target Variable SCATTER PLOT")

p71 <- ggplot(All, aes(x=Item_Weight,y=Item_Outlet_Sales)) +
          geom_boxplot(outlier.colour = "red4")

p72 <- ggplot(All, aes(x= Item_Visibility,y=Item_Outlet_Sales)) +
          geom_boxplot(outlier.colour = "red4")

p73 <- ggplot(All, aes(x= Item_MRP,y=Item_Outlet_Sales)) +
          geom_boxplot(outlier.colour = "red4")

grid.arrange(
          p71,p72,p73,nrow = 2,
          top = "Continuous Vs Target Variable BOX PLOT")
```
* Observations
* **Item_Outlet_Sales** is spread well across the entire range of the **Item_Weight**  without any obvious pattern.
* In **Item_Visibility vs Item_Outlet_Sales**, there is a string of points at **Item_Visibility = 0.0** which seems strange as item visibility cannot be completely zero.Also we can see the sudden decrease in of Products as Item visibility Increases. 
* In **Item_MRP vs Item_Outlet_Sales**, we can clearly see 4 segments of prices
* Extreme values are encounted in all Box Plots

### Target Variable vs Independent Categorical Variables

```{r}
# Discrete Vs Target Variable
p21 <- ggplot(Train,aes(Item_Fat_Content,Item_Outlet_Sales, fill = Item_Fat_Content)) + geom_boxplot()
p23 <- ggplot(Train,aes(Outlet_Size, Item_Outlet_Sales, fill = Outlet_Size)) + 
        geom_boxplot()
p24 <- ggplot(Train,aes(Outlet_Location_Type, Item_Outlet_Sales, fill = Outlet_Location_Type)) + 
        geom_boxplot()
p25 <- ggplot(Train,aes(Outlet_Type, Item_Outlet_Sales, fill = Outlet_Type)) + 
        geom_boxplot()

grid.arrange(
  p21,p25,p23,p24, nrow = 2,
  top = "Discrete Vs Target Variable")

```
* Extreme values are encounted in all Box Plots

```{r warning = FALSE}
ggplot(Train,aes(Item_Type,Item_Outlet_Sales, fill = Item_Type)) + 
  geom_boxplot() + coord_flip()

```
* As in the above BOX Plots we can see that there are many Extreme Values, therefore we have treat them later.

## **Data Preprocessing**

### Missing Value Treatment
```{r warning = FALSE}
# Getting missing value percentage
missing_val <- as.data.frame(sapply(All[,-c(12)], function(x) sum(is.na(x))/nrow(All[,-c(12)]) ))

# Renaming Column
colnames(missing_val) <- c("percent")
missing_val$col <-as.factor(row.names(missing_val))
missing_val <- filter( missing_val, percent > 0.0)

ggplot(missing_val, aes(y = percent,x = col, fill = col)) + 
  geom_bar(stat = "identity") + scale_y_continuous(breaks = seq(0,1, by =0.05)) +   ggtitle("Missing Values")

# Since there are more than 28% missing values in Outlet Size, therefore Dropping it.
All <- All[,-9]

# Replace Missing vaues in Item_Weight in mean
All = All %>% mutate_at(vars(Item_Weight),~ifelse(is.na(.x), mean(.x, na.rm = TRUE), .x))

# Total missing Values
sum(is.na(All[,-c(11)]))
```

### Replacing 0's in Item_Visibility variable
As there can be no variable whose **Visibility** could be zero. Therefore imputing it with mean.
```{r warning = FALSE}
# Since no item product can have zero visibility
ggplot(All, aes(Item_Visibility)) +
  geom_histogram( fill = "steelblue4", bins = 100)+ 
  scale_x_continuous(breaks = seq(0,0.5, by =0.05)) + ggtitle("Before Replacing")

## Replace 0 in Item_Visibility by Mean
# Count no of zeros
All %>% filter( Item_Visibility == 0.0 ) %>% count(n())
# Replace with mean
All = All %>% mutate(Item_Visibility = replace(Item_Visibility, 
                                                   which( Item_Visibility == 0.0),
                                                   mean(Train$Item_Visibility)))

ggplot(All, aes(Item_Visibility)) +
  geom_histogram( fill = "steelblue4", , bins = 100)+ 
  scale_x_continuous(breaks = seq(0,0.5, by =0.05))+ ggtitle("After Replacing")
```

## Feature Engineering

**Adding NEW Features**
1)
* Convering **Outlet_Establishment_Year** into Outlet Working Years  
```{r warning=FALSE}
# Get unique years
  sort(unique(All$Outlet_Establishment_Year))
  ## Replace year with corresponding number 
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 1985]<- 2018-1985
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 1987]<- 2018-1987
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 1997]<- 2018-1997
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 1998]<- 2018-1998
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 1999]<- 2018-1999
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 2002]<- 2018-2002
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 2004]<- 2018-2004
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 2007]<- 2018-2007
  All$Outlet_Establishment_Year[All$Outlet_Establishment_Year == 2009]<- 2018-2009

```

2)
* Converiting **Item_MRP** into categories
```{r}
ggplot(All, aes(Item_MRP)) +
      geom_histogram( fill = "purple4", na.rm = TRUE,binwidth = 1)+ 
      scale_x_continuous(breaks = seq(0,300, by =10))

# Gap 1
All %>% select(Item_MRP) %>% filter(Item_MRP >68 & Item_MRP < 71 )
# Gap 2
All %>% select(Item_MRP) %>% filter(Item_MRP >135 & Item_MRP < 137 )
# Gap 3
All %>% select(Item_MRP) %>% filter(Item_MRP >202 & Item_MRP < 204 )

# Creating new Column
All = All %>% mutate(Item_MRP_cluster = ifelse(Item_MRP < 69, "1st",      ifelse(Item_MRP >= 69 & Item_MRP < 136, "2nd",                              ifelse(Item_MRP >= 136 & Item_MRP < 203, "3rd", "4th"))))

# Converting into factors
All$Item_MRP_cluster<-as.factor(All$Item_MRP_cluster)

# Ploting
ggplot(All,aes(Item_MRP_cluster, fill = Item_MRP_cluster)) + 
  geom_bar()

```

3)
* Creating new Feature from **Item_Identifier**

As we know that in out dataset,
* **DR** --> Drinks
* **FD** --> Food
* **NC** --> Non Consumable
```{r}
library(stringr)
All = All %>% mutate( Item_Category = str_sub(Item_Identifier,start = 1, end =2 ))

# Replacing Values
All$Item_Category[All$Item_Category == "DR"] <- "Drinks"
All$Item_Category[All$Item_Category == "FD"] <- "Foods"
All$Item_Category[All$Item_Category == "NC"] <- "Non Consumable"

# Converting into Factors
All$Item_Category <- as.factor(All$Item_Category)
levels(All$Item_Category)

# Ploting
ggplot(All,aes(Item_Category, fill = Item_Category)) + 
  geom_bar()

```

4)
* Creating new Feature from **Outlet_Identifier**
```{r}
# Ploting
ggplot(All,aes(as.factor(Outlet_Identifier), fill = Outlet_Identifier)) + 
    geom_bar() + xlab("Outlet Identifier") + ggtitle("Old Plot")

# Creating new Column
All$Outlet_Type_New <- as.factor(All$Outlet_Identifier)

# Renaming Levels
levels(All$Outlet_Type_New) <- c("OutLet 1","OutLet 2","OutLet 3","OutLet 4","OutLet 5","OutLet 6","OutLet 7","OutLet 8","OutLet 9","OutLet 10")

# Drop Outlet Identifier
All <- All[,-c(7)]

# new Ploting
ggplot(All,aes(as.factor(Outlet_Type_New), fill = Outlet_Type_New)) + geom_bar() + xlab("Outlet Type NEW") + ggtitle("New Plot")
```

5)
* Creating new Feature from **Item_MRP and Item_Weight**
```{r}

All = All %>% mutate( Item_MRP_per_unit_Weight = All$Item_MRP/All$Item_Weight)

# Ploting 
ggplot(All, aes(Item_MRP_per_unit_Weight,Item_Outlet_Sales))+
        geom_point(colour = 'darkorchid4',alpha=0.3)
```

6)
Trying to combine Item_Type(16 levels) into smaller Types
```{r}
# Creating Table
kable(table(All$Item_Type,All$Item_Category), caption = "Tabel 1")
kable(table(All$Item_Type,All$Item_Fat_Content), caption = "Tabel 2")


perishable = c("Breads", "Breakfast", "Dairy", "Fruits and Vegetables", "Meat", "Seafood")
non_perishable = c("Baking Goods", "Canned", "Frozen Foods", "Hard Drinks", "Health and Hygiene", "Household", "Soft Drinks")

# create a new feature 'Item_Type_new'
All <- All %>% mutate(Item_Type_New = ifelse(Item_Type %in% perishable, "perishable", ifelse(Item_Type %in% non_perishable, "non_perishable", "not_sure")))

All$Item_Type_New <- as.factor(All$Item_Type_New)
# Dropping Item Type
All <- All[,-c(5)]

```



```{r}
#str(All )
All$Outlet_Location_Type <- as.factor(All$Outlet_Location_Type)
All$Outlet_Type <- as.factor(All$Outlet_Type)
```

### Removing Skewness 

Checking Skewness of Continuous Variables
```{r}
library(moments)
cat("Skewness of Item_Weight is :",skewness(All$Item_Weight),
    "Skewness of Item_Visibility is :",skewness(All$Item_Visibility),
    "Skewness of Item_MRP is :",skewness(All$Item_MRP),
    "Skewness of Item_MRP_per_unit_Weight is :",skewness(All$Item_MRP_per_unit_Weight),fill =2)
```
In the above giving Result, as we can see that **Item_Visibility**,and **Item_MRP_per_unit_Weight** are
highly skewed.

```{r}
All$Item_Visibility <- All$Item_Visibility^(1/3)
All$Item_Weight <- sqrt(All$Item_Weight)
All$Item_MRP_per_unit_Weight <- All$Item_MRP_per_unit_Weight^(1/3)

```

Scaling Numeric Variables and Creating Dummy Variables
```{r}
# Other than numeric Variables
set_2 <- All[,-c(2,4,6,14)]

# standardizing the Variables
set_1 <- normalizeFeatures(All[,c(2,4,6,14)],method = "standardize")

# Combining Sets
All_trans <- bind_cols( set_1, set_2)

# Creating Dummy Variable using MLR Pakage 
All_trans <- createDummyFeatures(All_trans)
```

Splitting the combined data All back to train and test set.
```{r}
train <- All_trans[1:nrow(Train),]
test <- All_trans[(nrow(Train)+1):nrow(All_trans),]

# Removing Item_Outlet_Sales from test set
test <- test[, -c(8)] 
```



### Correlation Between Variables 
```{r warning=FALSE}
# Making Correlation Matrix
library(corrplot)
cor_train = cor(train[,-c(4)])
corrplot(cor_train, method = "pie", type = "lower")

```

Obsevations
* There are some highly correlated variables, therefore we have to remove them.

```{r}
# Converting into dataframe
cor_train <- as.data.frame(cor_train)

# making new columns from row names
cor_train <- cor_train %>% mutate( var_names = row.names(cor_train))

# filter having high correlation with Item Outlet Sales
kable(cor_train %>% select(var_names, Item_Outlet_Sales) %>% filter(Item_Outlet_Sales >0.3 | Item_Outlet_Sales < -0.3 ))

# Dropping highly correlated variables from train set
train <- train[!(names(train)) %in% c('Outlet_Type_New.Outlet.4','Outlet_Type_New.Outlet.6','Outlet_Type_New.OutLet.5','Outlet_Type_New.OutLet.1','Item_Category.Non.Consumable','Item_MRP_cluster.4th','Item_Fat_Content.Low.Fat')]

# Dropping highly correlated variables from test set
test <- test[!(names(test)) %in% c('Outlet_Type_New.Outlet.4','Outlet_Type_New.Outlet.6','Outlet_Type_New.OutLet.5','Outlet_Type_New.OutLet.1','Item_Category.Non.Consumable','Item_MRP_cluster.4th','Item_Fat_Content.Low.Fat')]

```

### Split Train Dataset
```{r}
library(caTools)
set.seed(123)
split = sample.split(train$Item_Outlet_Sales, SplitRatio = 0.8)
train_set = subset(train[,-c(1)] , split==TRUE )
valid_set = subset(train[,-c(1)]  , split==FALSE ) 
```


### Model 1
```{r}

# Creating a task
ml_task <- makeRegrTask(data = train_set[,-c(3)],target = 'Item_Outlet_Sales')

# Making a learner
# Regression RandomForest model
rf.lrn <- makeLearner("regr.randomForest",par.vals = list(ntree = 1000,
                                                          mtry = 10,
                                                          maxnodes = 40,
                                                          importance = TRUE))
# To get the list of parameters for any algorithm
# getParamSet("regr.randomForest")

# Define Hyperparameters of model
model_Params <- makeParamSet(
  makeIntegerParam("ntree",lower = 500, upper = 1200),
  makeIntegerParam("mtry",lower = 3, upper = 12),
  makeIntegerParam("maxnodes",lower = 20, upper = 50)
)

# Define model tuning algorithm ~ Random tune algorithm
# Random Search on the space
random_tune <- makeTuneControlRandom(maxit = 100L)

# Create repeated cross validation folds
cv_folds <- makeResampleDesc("CV", iters = 3) # 3 fold cross validation

# Tune model to find best performing parameter settings 
# using random search algorithm
tuned_model <- tuneParams(learner = rf.lrn,
                          task = ml_task,
                          resampling = cv_folds,
                          measures = mlr::rmse,       
                          par.set = model_Params,
                          control = random_tune,
                          show.info = FALSE
                          )

# Apply optimal parameters to model
model <- setHyperPars(learner = model,
                      par.vals = tuned_model$x)


# Verify performance on cross validation folds of tuned model
# resample(model,ml_task,cv_folds,measures = list(rsq,mlr::rmse))


rf <- train(learner = rf.lrn,task = ml_task)
rf_pred <- predict(rf,newdata = valid_set)
performance(rf_pred,measures = mlr::rmse)


# creating Submission file
Item_Outlet_Sales <- predict(rf, newdata = Test_trans[,pred_var])
submission_file = data.frame(col1 = Test$Item_Identifier,col2 = Test$Outlet_Identifier,
                             col3 = Item_Outlet_Sales)
colnames( submission_file) <- c("Item_Identifier","Outlet_Identifier","Item_Outlet_Sales")

write.csv(submission_file, file = "C:\\Users\\RISHABH\\Desktop\\sub_file.csv", row.names = FALSE)

# 1194
 
```




 
